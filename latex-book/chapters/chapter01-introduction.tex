\chapter{Introduction to Optimization and Evolutionary Computation}

\section{Overview}
This chapter provides a foundational understanding of optimization problems and introduces the concept of evolutionary computation as a powerful approach to solving complex optimization challenges.

\section{What is Optimization?}
Optimization is the process of finding the best solution from a set of available alternatives. In mathematical terms, an optimization problem can be formulated as:

\begin{equation}
\begin{aligned}
\text{minimize (or maximize)} \quad & f(x) \\
\text{subject to} \quad & g_i(x) \leq 0, \quad i = 1, 2, \ldots, m \\
& h_j(x) = 0, \quad j = 1, 2, \ldots, p \\
& x \in X
\end{aligned}
\end{equation}

where:
\begin{itemize}
    \item $f(x)$ is the objective function to be optimized
    \item $g_i(x)$ are inequality constraints
    \item $h_j(x)$ are equality constraints
    \item $X$ is the feasible region
\end{itemize}

\section{Types of Optimization Problems}
\subsection{Based on Variable Types}
\begin{itemize}
    \item \textbf{Continuous Optimization}: Variables can take any real value
    \item \textbf{Discrete Optimization}: Variables can only take discrete values
    \item \textbf{Mixed-Integer Optimization}: Combination of continuous and discrete variables
\end{itemize}

\subsection{Based on Problem Characteristics}
\begin{itemize}
    \item \textbf{Linear Programming}: Objective function and constraints are linear
    \item \textbf{Nonlinear Programming}: At least one function is nonlinear
    \item \textbf{Convex Optimization}: Objective function is convex
    \item \textbf{Multi-objective Optimization}: Multiple conflicting objectives
\end{itemize}

\section{Traditional Optimization Methods}
Traditional optimization methods include:
\begin{itemize}
    \item Gradient-based methods (Newton's method, quasi-Newton methods)
    \item Simplex method for linear programming
    \item Branch and bound for integer programming
    \item Dynamic programming
\end{itemize}

\subsection{Limitations of Traditional Methods}
\begin{itemize}
    \item Require differentiability of objective function
    \item Can get trapped in local optima
    \item Computationally expensive for large-scale problems
    \item Difficulty handling discrete variables
    \item Problems with discontinuous or noisy functions
\end{itemize}

\section{Introduction to Evolutionary Computation}
Evolutionary computation is a family of algorithms inspired by biological evolution~\cite{holland1975adaptation, eiben2015introduction}. These algorithms use mechanisms such as:
\begin{itemize}
    \item \textbf{Selection}: Survival of the fittest
    \item \textbf{Reproduction}: Creating offspring
    \item \textbf{Mutation}: Random changes
    \item \textbf{Crossover}: Combining genetic material
\end{itemize}

\subsection{Advantages of Evolutionary Approaches}
\begin{itemize}
    \item No requirement for gradient information
    \item Can handle discontinuous, noisy, and multi-modal functions
    \item Suitable for both continuous and discrete optimization
    \item Population-based search provides robustness
    \item Can find global optima
\end{itemize}

\section{Types of Evolutionary Algorithms}
\begin{itemize}
    \item \textbf{Genetic Algorithms (GA)}: Inspired by natural selection~\cite{holland1975adaptation, goldberg1989genetic}
    \item \textbf{Evolution Strategies (ES)}: Focus on real-valued optimization~\cite{back1996evolutionary}
    \item \textbf{Evolutionary Programming (EP)}: Emphasis on behavioral evolution~\cite{fogel1995evolutionary, fogel2006evolutionary}
    \item \textbf{Genetic Programming (GP)}: Evolution of computer programs~\cite{koza1992genetic}
\end{itemize}

\section{Applications of Evolutionary Computation}
Evolutionary algorithms have been successfully applied to~\cite{gen2007genetic, sivanandam2008introduction, eiben2015introduction}:
\begin{itemize}
    \item Engineering design optimization~\cite{yildiz2023novel}
    \item Machine learning and neural network training~\cite{montana1989training, murad2025hybrid}
    \item Scheduling and timetabling~\cite{gu2022hybrid, fajrin2020multi}
    \item Financial modeling
    \item Bioinformatics
    \item Game playing and strategy
\end{itemize}

\section{Simple Examples of Genetic Algorithm Applications}

Genetic Algorithms possess an extraordinary capability in finding optimal solutions for problems with vast search spaces.

\subsection{Maximizing a Quadratic Function}
A classic example often used to illustrate how Genetic Algorithms work is the problem of maximizing a simple quadratic function, such as $f(x) = x^2$ in the range $0 \leq x \leq 31$. In this case, the optimal solution is clear: $x = 31$, yielding $f(x) = 961$. However, this problem is used to demonstrate how Genetic Algorithms, despite starting with a random population (for example, four 5-bit binary chromosomes), can gradually combine features (building blocks) from existing solutions to achieve better results.

Through cycles of selection, crossover, and mutation, Genetic Algorithms show how both the maximum and average performance of the population increases from one generation to the next. Within a few generations, individuals representing $x = 31$ (binary 11111) will dominate the population.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{figures/buku_ajar_page_4.png}
\caption{Illustration of GA cycle and variations}
\label{fig:ga_intro_cycle}
\end{figure}

\subsection{Travelling Salesman Problem}
Another example of genetic algorithm application is the Travelling Salesman Problem (TSP), where Genetic Algorithms are used to find the shortest route visiting a number of citiesâ€”a highly complex combinatorial optimization problem.

\section{Genetic Algorithms for Real-World Problems}

Genetic Algorithms are becoming increasingly popular in industrial engineering, management science, and operations research due to their capability in handling complex optimization problems. Many real-world engineering problems are too complex, non-linear, or contain intricate constraints that are difficult to solve with conventional methods. Genetic Algorithms offer a robust and widely applicable method for stochastic search and optimization.

Rather than searching for a single solution point, Genetic Algorithms work on a population of solutions and only require the objective function (fitness) value without requiring derivatives or deep prior knowledge about the search space~\cite{mitchell1996introduction, goldberg1989genetic}. This makes Genetic Algorithms highly suitable for problems such as:

\subsection{Scheduling}
Scheduling problems, such as course scheduling~\cite{fajrin2020multi}, factory production scheduling (Job Shop Scheduling)~\cite{gu2022hybrid, reeves1998genetic}, or flight scheduling, are combinatorial optimization problems characterized by a large number of tasks, limited resources, and strict time constraints. In this context, GA chromosomes represent one task sequence or allocation (schedule). The fitness function is designed to minimize criteria such as total completion time (makespan), amount of delays, or operational costs. Genetic Algorithms can navigate discrete and large solution spaces very efficiently, searching for the best task sequence that meets all complex constraints.

\subsection{Telecommunication Network Design}
In network design, Genetic Algorithms are used to optimize topology, capacity, and node or router placement to achieve the best performance. The goal is often to minimize network construction costs while maximizing service quality, such as minimizing delay or maximizing throughput. Chromosomes can encode connection configurations between nodes or technology choices. Because each configuration change can significantly impact overall network performance, Genetic Algorithms are very useful for exploring various possible network architectures that are mathematically difficult to solve with traditional methods.

\subsection{VLSI Design (Very Large Scale Integration)}
VLSI is the process of designing semiconductor chips with millions of transistors. Genetic Algorithms are highly relevant in two main sub-problems: placement and routing. In the placement problem, Genetic Algorithms optimize the position of circuit blocks on the chip to minimize total wire length and avoid overlaps. In routing, Genetic Algorithms search for the best path to connect all circuit pins without violating physical constraints. The high dimensionality and geometric constraints (such as area, power, and timing) make the VLSI search space explosive, making Genetic Algorithms a feasible search technique for generating near-optimal layouts.

\section{Genetic Algorithm Flow}

Genetic algorithms maintain a population of individuals, denoted as $P(t)$ for generation $t$, where each individual represents a potential solution to the problem at hand. This cycle runs iteratively through steps that mimic the evolution process.

After the initial population $P(0)$ is initialized and its fitness evaluated, the selection process begins, where fitter individuals are probabilistically selected to enter the mating pool. Selected individuals then undergo stochastic transformation through genetic operators. The crossover operator is responsible for exploiting the best information from parents, while mutation is tasked with exploring the search space by introducing new genetic material.

Newly generated individuals, called offspring $C(t)$, are then evaluated for their fitness. A new population $P(t+1)$ is formed by selecting fitter individuals from both the parent and offspring populations through a replacement scheme. This process is repeated for several generations until the algorithm converges, pointing to the best individual, which is expected to represent an optimal or suboptimal solution to the problem.

\section{Genetic Algorithm Variations}

Although the Simple Generational Genetic Algorithm serves as the basic framework, various modifications have been developed to improve performance in dealing with problem complexity. Some of these modifications include:

\subsection{Hybrid GA}
Hybrid GA (HGA) combines Genetic Algorithms with conventional local search techniques~\cite{majhi2025novel, murad2025hybrid}. In a hybrid approach, Genetic Algorithms perform global exploration across the population, while local search is used for refinement around promising solutions. This approach often outperforms single methods because it leverages the complementary advantages of both search techniques.

\subsection{Adaptive GA}
Adaptive GA (AGA) is a Genetic Algorithm where strategic parameters (such as crossover or mutation probabilities) are dynamically adjusted during the evolution process, often using feedback from population performance to balance exploitation and exploration effectively~\cite{shams2025resolving, srinivas1994genetic}.

\subsection{Parallel GA}
Parallel Genetic Algorithms divide the population into different sub-populations across various processors, allowing periodic information exchange (migration) to increase diversity and convergence speed.

\section{Chapter Summary}
This chapter introduced the fundamental concepts of optimization and evolutionary computation. We explored the limitations of traditional optimization methods and highlighted the advantages of evolutionary approaches. We also examined specific examples of GA applications including function optimization, TSP, scheduling, network design, and VLSI design. The GA flow and various modifications were discussed to provide a comprehensive understanding of genetic algorithms.

\section{Key Concepts}
\begin{itemize}
    \item Optimization problem formulation
    \item Objective functions and constraints
    \item Local vs. global optima
    \item Evolutionary computation principles
    \item Population-based search
\end{itemize}

\section{Further Reading}
\begin{itemize}
    \item Deb, K. (2001). Multi-objective optimization using evolutionary algorithms.
    \item Eiben, A. E., \& Smith, J. E. (2015). Introduction to evolutionary computing.
    \item Goldberg, D. E. (1989). Genetic algorithms in search, optimization, and machine learning.
\end{itemize}