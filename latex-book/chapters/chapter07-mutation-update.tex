\chapter{Mutation and Generation Update}
\label{ch:mutation-update}

In the previous chapters, we have covered the fundamental operations of Genetic Algorithms (GA) including encoding, fitness evaluation, selection, and crossover. This chapter completes the discussion of GA operators by examining \textbf{mutation} and \textbf{generation update mechanisms}~\cite{course_week9, tutorialspoint_mutation}. These operations are crucial for maintaining genetic diversity and ensuring the algorithm's ability to explore the search space effectively.

\section{Introduction to Mutation}
After the recombination (crossover) stage has been applied to all pairs of chromosomes in the mating pool, producing $N$ chromosomes (where $N$ is the population size), the GA executes the mutation operator on each of these chromosomes. Mutation is a critical operator that prevents premature convergence to local optima, maintains genetic diversity in the population, introduces new genetic material that may not have been present in the initial population, and provides a mechanism for escaping local optima.
Mutation plays a critical role immediately after recombination. By introducing stochastic changes to one or more genes, mutation reduces the risk of premature convergence, sustains genetic diversity across generations, and injects new alleles that may not exist in the initial population. These effects together provide a mechanism for escaping local optima and for exploring regions of the search space that recombination alone cannot reach. Although the mutated population is not guaranteed to be fitter than its predecessors, mutation is an essential exploration tool in the GA toolbox.

\subsection{What is Mutation?}

Mutation is the process of changing the value of one or more genes in a genome~\cite{goldberg1989genetic, mitchell1996introduction, back1996evolutionary}. More specifically, it may change the allele of a gene at a specific locus to another allele, help avoid premature convergence (which is reaching a suboptimal result that is not the global maximum), and create offspring that are not necessarily better than their parents.
Concretely, a mutation alters one or more gene values (alleles) at chosen loci. This alteration can be random or follow a simple stochastic rule; its primary purpose is to maintain variation in the population so that the search process can continue to explore promising and novel regions of the fitness landscape. Mutations sometimes produce inferior offspring, but they are often the only mechanism capable of introducing novel building blocks that lead to future improvements.

\textbf{Important Note:} The new population resulting from mutation is not guaranteed to be better than the previous population. However, mutation provides the essential mechanism for maintaining diversity and exploring new regions of the search space.

\subsection{Mutation in Evolutionary Algorithms vs. Biological Evolution}

In biological evolution, mutation is typically considered harmful because complex organisms have highly interdependent systems. However, in Evolutionary Algorithms (EAs):
Although biological mutations are often deleterious in complex organisms, the situation in Evolutionary Algorithms is different. Representations used in EAs are typically far simpler and more modular than biological genomes, so small, localized changes can produce constructive variations. As a result, mutation in EAs can frequently generate beneficial diversity: mutating a small subset of genes may yield improved offspring without disrupting other functional components of the solution.

\section{Mutation for Different Representations}

Many mutation methods have been proposed in the literature~\cite{michalewicz1996genetic, back1996evolutionary, haupt2004practical}. Each method has special characteristics and may only be applicable to certain types of representations. The choice of mutation operator must be compatible with the chromosome encoding scheme. 

\subsection{Mutation for Binary Representation}
\label{sec:binary-mutation}

Binary representation uses the simplest form of mutation: \textbf{bit-flip mutation}.

\subsubsection{Bit-Flip Mutation}
In bit-flip mutation, each bit in the chromosome has a probability $P_m$ (mutation probability) of being flipped: a bit with value $1$ becomes $0$, and a bit with value $0$ becomes $1$.
In binary encodings the simplest mutation is bit-flip: each bit is independently flipped with probability $P_m$, so a 1 becomes 0 and vice versa. This operator is minimal and unbiased, and when $P_m$ is small it provides rare but meaningful perturbations to otherwise stable bit-strings.

\textbf{Example:}
\begin{verbatim}
Parent:    1 0 1 1 0 1 0 0
                 ^     ^
Offspring: 1 0 0 1 0 0 0 0
\end{verbatim}

In this example, bits at positions 3 and 6 were selected for mutation and flipped.

\textbf{Algorithm:}
\begin{algorithm}[H]
\caption{Bit-Flip Mutation}
\begin{algorithmic}
\FOR{each gene $g_i$ in chromosome}
    \STATE $r \gets$ random number in $[0,1]$
    \IF{$r < P_m$}
        \STATE Flip $g_i$: if $g_i = 1$ then $g_i \gets 0$, else $g_i \gets 1$
    \ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}

\subsection{Mutation for Integer Representation}
\label{sec:integer-mutation}

Integer representations require different mutation strategies. Common approaches include integer value flipping, random value selection, and creep mutation.

\subsubsection{Integer Value Flipping}

Uses mathematical operations ($+$, $-$, $\times$, $\div$) to change the value of selected genes.

\textbf{Example:}
\begin{verbatim}
Parent:    8  3  7  5  2  1  9  4  6
                 ^        ^
Offspring: 8  3  2  5  2  8  9  4  6
\end{verbatim}

The values at positions 3 and 6 were changed using mathematical operations.

\subsubsection{Random Value Selection}

A selected gene is replaced with a randomly chosen value from the valid range.

\textbf{Example:}
If the valid range is $[1, 9]$:
\begin{verbatim}
Parent:    8  3  7  5  2  1  9  4  6
                    ^
Offspring: 8  3  7  9  2  1  9  4  6
\end{verbatim}

\subsubsection{Creep Mutation}

Adds or subtracts a small random integer value (usually $\pm 1$ or $\pm 2$) to the selected gene.

\textbf{Example:}
\begin{verbatim}
Parent:    8  3  7  5  2  1  9  4  6
              ^           ^
Offspring: 8  4  7  5  2  2  9  4  6
\end{verbatim}

This method makes small, gradual changes and is particularly useful for fine-tuning solutions.

\subsection{Mutation for Real-Valued Representation}
\label{sec:real-mutation}

Real-valued representations have different characteristics from binary and integer representations. Values of genes in real representations are continuous, whereas binary and integer representations are discrete. Therefore, real representations require specialized mutation operators.

\subsubsection{Uniform Mutation}
In uniform mutation, selected genes are replaced with values drawn from a uniform random distribution within the valid range $[a, b]$:

\begin{equation}
x_i' = a + \text{rand}(0,1) \times (b - a)
\end{equation}

where:
\begin{itemize}
    \item $x_i'$ is the new gene value
    \item $a$ and $b$ are the lower and upper bounds
    \item $\text{rand}(0,1)$ generates a random number in $[0, 1]$
\end{itemize}

\subsubsection{Non-Uniform Mutation with Fixed Distribution}

This mutation is similar to the creep method for integer representations but uses real-valued additions. The mutated value is calculated as:

\begin{equation}
x_i' = x_i + \mathcal{N}(0, \sigma^2)
\end{equation}

where:
\begin{itemize}
    \item $x_i$ is the original gene value
    \item $\mathcal{N}(0, \sigma^2)$ is a random value from a normal (Gaussian) distribution with mean 0 and variance $\sigma^2$
    \item $\sigma$ controls the mutation step size
\end{itemize}

\textbf{Example:}
\begin{verbatim}
Parent:    2.45  7.89  3.12  9.01  5.67
                       ^
Offspring: 2.45  7.89  3.45  9.01  5.67
\end{verbatim}

\subsection{Mutation for Permutation Representation}
\label{sec:permutation-mutation}

Mutation on permutation representations must ensure that the resulting chromosome remains valid (all elements appear exactly once). Specialized methods have been developed to preserve validity while introducing variation.

\subsubsection{Swap Mutation}

Two gene positions are randomly selected, and their values are exchanged.

\textbf{Example:}
\begin{verbatim}
Parent:    3  1  5  2  7  6  8  4  9
              ^           ^
Offspring: 3  1  8  2  7  6  5  4  9
\end{verbatim}

Positions 3 and 7 are selected, so values 5 and 8 are swapped.

\textbf{Algorithm:}
\begin{algorithm}[H]
\caption{Swap Mutation}
\begin{algorithmic}
\STATE $i \gets$ random position in chromosome
\STATE $j \gets$ random position in chromosome (different from $i$)
\STATE Swap values at positions $i$ and $j$
\end{algorithmic}
\end{algorithm}

\subsubsection{Insert Mutation}

A gene at one position is removed and inserted at another position, shifting the intermediate genes.

\textbf{Example:}
\begin{verbatim}
Parent:    3  1  5  2  7  6  8  4  9
              ^           ^
Offspring: 3  1  5  2  7  8  6  4  9
\end{verbatim}

The gene at position 7 (value 8) is removed and inserted after position 2 (value 5).

\subsubsection{Scramble Mutation}

A segment of the chromosome is selected, and the genes within that segment are randomly shuffled.

\textbf{Example:}
\begin{verbatim}
Parent:    3  1  5  2  7  6  8  4  9
              \_______/
Offspring: 3  1  2  6  5  7  8  4  9
\end{verbatim}

The segment $\{5, 2, 7, 6\}$ is selected and randomly shuffled to $\{2, 6, 5, 7\}$.

\subsubsection{Inversion Mutation}

A segment of the chromosome is selected, and the order of genes within that segment is reversed.

\textbf{Example:}
\begin{verbatim}
Parent:    3  1  5  2  7  6  8  4  9
              \_______/
Offspring: 3  1  6  7  2  5  8  4  9
\end{verbatim}

The segment $\{5, 2, 7, 6\}$ is reversed to $\{6, 7, 2, 5\}$.

\section{Generation Update Mechanisms}

After selection, crossover, and mutation operations have been applied to a population, a generation update mechanism determines which individuals survive to the next generation. This process is also called \textbf{survivor selection} or \textbf{replacement strategy}. 

\subsection{Holland's Original Model (Generational Replacement)}
\label{sec:holland-update}
In Holland's original GA~\cite{holland1975adaptation, goldberg1989genetic} all offspring replace the entire parent population. Parents are considered "dead" and removed, so the new population consists entirely of offspring and generations are distinct and non-overlapping.
In Holland's original generational replacement model, the offspring population entirely replaces the parents, producing distinct, non-overlapping generations. The model is simple and easy to implement and provides a clear separation between generations. A practical drawback is the potential loss of high-quality parents unless mechanisms such as elitism are used to preserve them.

\subsection{Generational Model with Elitism}
\label{sec:elitism}

In the generational model with elitism, a population of size $N$ chromosomes in one generation is replaced by $N$ new individuals in the next generation~\cite{de1975analysis, whitley1994genetic}. However, to preserve the best solutions, the best $k$ chromosomes (elites) from the parent generation are copied directly to the next generation while the remaining $N-k$ positions are filled with offspring; this ensures that the best solution never gets worse across generations.
In the generational model with elitism, the top $k$ individuals from the parent generation are carried forward unchanged and the remaining $N-k$ positions are filled by newly generated offspring. This simple modification guarantees that the best-so-far solutions are not lost, which stabilizes the search and often speeds convergence. Typical choices of $k$ are small (e.g. 1 or 2), balancing preservation and exploration.

\textbf{Algorithm:}
\begin{algorithm}[H]
\caption{Generational Model with Elitism}
\begin{algorithmic}
\STATE Sort parent population by fitness
\STATE Copy top $k$ individuals to next generation (elites)
\STATE Generate $N-k$ offspring through selection, crossover, and mutation
\STATE Add offspring to next generation
\STATE Next generation becomes current generation
\end{algorithmic}
\end{algorithm}

\textbf{Typical values:} $k = 1$ or $k = 2$ (preserving 1-2 best individuals)

\subsection{Steady-State Update}
\label{sec:steady-state}

In the steady-state model~\cite{whitley1994genetic, smith1998replacement} not all chromosomes are replaced in each generation; only $M$ chromosomes are replaced where $M < N$ (often $M = 2$, when one mating produces two offspring which replace two individuals). Replacement strategies include: \textbf{replace parents} (the two offspring replace their two parents), \textbf{replace worst} (the two offspring replace the two worst individuals), and \textbf{replace oldest} (the two offspring replace the two oldest individuals). This model allows good individuals to participate in multiple matings, produces more gradual evolution, lets parents and offspring coexist in the same population, and can be more efficient computationally.
In steady-state update schemes only a small number $M$ of individuals (with $M<N$) are replaced at each step, which permits parents and offspring to coexist and allows high-quality individuals to be reused in multiple matings. Common replacement strategies are replacing the parents of the offspring, replacing the worst individuals found in the population, or replacing the oldest individuals; each strategy emphasizes different trade-offs between preserving diversity and intensifying selection. The steady-state approach typically yields more gradual evolution and can be computationally efficient when $M$ is small.

\subsection{Continuous Update}
\label{sec:continuous-update}

In continuous update offspring and parents can coexist in the same generation; individuals are selected randomly from both groups for the next generation, providing maximum overlap between generations. This method is less commonly used than other update methods.
Continuous update schemes allow full coexistence of parents and offspring and typically select individuals for survival from the combined set. This produces maximum generational overlap and a highly mixed population, though in practice such schemes are less commonly employed compared to generational or steady-state replacements.

\section{GA Parameters}

The performance of a Genetic Algorithm heavily depends on proper parameter settings~\cite{grefenstette1986optimization, schaffer1989study, de1975analysis}. The main parameters that need to be configured are: 

\subsection{Crossover Probability ($P_c$)}
\label{sec:crossover-probability}

$P_c$ is the probability that two parents will undergo crossover. If $P_c=100\%$, all offspring are produced through crossover; if $P_c=0\%$, no crossover occurs and offspring are exact copies of parents. Typical values lie in the range $P_c\in[0.65,0.90]$. Higher values (0.8–0.9) encourage exploration, while lower values preserve good solutions but reduce diversity; a standard starting setting is $P_c=0.8$.
The crossover probability $P_c$ controls how often recombination occurs. Values near 1 (e.g. 0.8–0.9) encourage aggressive mixing of parental material and therefore exploration of the search space, while lower values conserve parental structures and slow the creation of novel combinations. A commonly used default is $P_c\approx0.8$, but the final choice depends on problem characteristics and empirical tuning.

\subsection{Mutation Probability ($P_m$)}
\label{sec:mutation-probability}

$P_m$ is the probability that a gene in an offspring chromosome will undergo mutation. When $P_m=100\%$ all genes are mutated (leading to chaos), and when $P_m=0\%$ no mutation occurs and no new genetic material is introduced. Typical values are small, e.g. $P_m\in[0.005,0.01]$ (0.5%–1%). Common formulas are
Typical mutation probabilities are very small so that mutations occur infrequently; values in the range $0.5\%$ to $1\%$ per gene are common starting points. Two commonly used heuristics are $P_m=1/L$ (one mutation per chromosome on average) or $P_m=1/(N\times L)$ when scaling mutation relative to total evaluations. Setting $P_m$ too high destroys useful structure, while setting it too low can allow premature convergence through loss of diversity.
\begin{equation}
P_m = \frac{1}{L}
\end{equation}
or
\begin{equation}
P_m = \frac{1}{N \times L}
\end{equation}

where:
\begin{itemize}
    \item $L$ is the chromosome length (number of genes)
    \item $N$ is the population size
\end{itemize}

\textbf{Rationale:} The mutation probability is often set so that, on average, one mutation occurs per chromosome.

\subsection{Population Size ($N$)}
\label{sec:population-size}

The population size should be proportional to the volume of the search space. If the population is too small it may be difficult to reach the global optimum and the search may converge to local optima; if the population is too large it imposes heavy computational cost and can be unnecessary. Typical ranges are $N\in[50,100]$, but the exact value should be determined through experimentation and chosen according to problem complexity and available computational resources.
Population size $N$ mediates the trade-off between exploratory coverage of the search space and computational cost. Small populations can fail to represent sufficient diversity and may converge to local optima, while excessively large populations increase runtime without proportional gains. As a practical guideline, many problems start with $N$ between 50 and 100 and then adjust based on empirical performance and available compute resources.

\subsection{Number of Generations ($G$)}
\label{sec:num-generations}

The number of generations should be proportional to population size and search space size.
The number of generations $G$ should be chosen in relation to $N$ and the complexity of the search space: larger or more complex problems typically require more generations to converge. Common stopping criteria include a fixed number of generations, a maximum number of fitness evaluations, no improvement for $k$ consecutive generations, reaching a target fitness, or a suitable combination of these conditions.

\subsection{General Parameter Setting Guidelines}
\label{sec:parameter-guidelines}

	extbf{Important Note:} There are no universal rules for choosing GA parameters~\cite{wolpert1997no, grefenstette1986optimization}. Good settings are typically found through a combination of theoretical heuristics, prior experience, and systematic experimentation. A reasonable starting configuration is to choose a representation suited to the problem (binary, integer, real or permutation), set population size $N$ in the tens to low hundreds (e.g. 50–100), use $P_c\approx0.8$, and set mutation heuristics such as $P_m\approx1/L$ (or scaled variants like $1/(N\times L)$) with subsequent tuning based on results.

\section{Parameter Observation Study}

To understand the effects of different parameters, we present a systematic observation study.

\subsection{Test Problem}

\textbf{Objective:} Minimize the function:
\begin{equation}
h(x_1, x_2) = x_1^2 + x_2^2
\end{equation}

where $x_1, x_2 \in [-10, 10]$

\textbf{Fitness function:}
\begin{equation}
\text{Fitness} = \frac{1}{x_1^2 + x_2^2 + 0.001}
\end{equation}

The constant 0.001 is added to avoid division by zero at the optimal point $(0, 0)$.

\subsection{Experimental Setup}
	extbf{Experimental setup:} The study varied population size (50, 100, 200), bit precision per variable (10, 50, 90), crossover probability ($P_c\in\{0.5,0.7,0.9\}$), and mutation probability relative to chromosome length (e.g. $0.5/L,\;1/L,\;2/L$). To ensure fair comparisons, each configuration was constrained by a maximum of 20,000 evaluated individuals and was repeated 30 times to obtain reliable statistics.

\subsection{Sample Results}

Table~\ref{tab:ga-parameters} shows selected results from the parameter study:

\begin{table}[H]
\centering
\caption{GA Parameter Observation Results}
\label{tab:ga-parameters}
\begin{tabular}{cccccc}
\toprule
\textbf{Pop Size} & \textbf{Bits} & \textbf{$P_c$} & \textbf{$P_m$} & \textbf{Avg Best Fitness} & \textbf{Avg Evaluations} \\
\midrule
50  & 10 & 0.5 & 0.0250 & 839.55 & 20000 \\
50  & 50 & 0.5 & 0.0050 & 1000.00 & 8301.67 \\
50  & 50 & 0.7 & 0.0100 & 1000.00 & 20000 \\
50  & 90 & 0.7 & 0.0056 & 1000.00 & 8780.00 \\
100 & 50 & 0.7 & 0.0050 & 1000.00 & 14416.67 \\
100 & 90 & 0.5 & 0.0111 & 1000.00 & 20000 \\
200 & 50 & 0.5 & 0.0050 & 1000.00 & 20000 \\
200 & 90 & 0.7 & 0.0056 & 1000.00 & 20000 \\
200 & 90 & 0.9 & 0.0028 & 1000.00 & 19866.67 \\
\bottomrule
\end{tabular}
\end{table}

	extbf{Key observations:} The most efficient configuration in these experiments was population size 50 with 90 bits per variable, $P_c=0.7$ and $P_m\approx0.0056$, which consistently reached the optimum (fitness 1000.00) while requiring only about 8780 evaluations on average. Regarding precision, 10 bits were often insufficient to reach the optimum, while 50–90 bits provided the necessary granularity for reliable convergence. Smaller populations (e.g. 50) proved efficient in this test problem, whereas larger populations (e.g. 200) offered more robustness at greater computational cost — a classic speed-versus-reliability trade-off. Crossover probabilities around 0.7 tended to balance exploration and exploitation effectively. Finally, low mutation rates on the order of $1/L$ worked best: rates that were too high introduced disruptive randomness, while rates that were too low reduced diversity and risked premature convergence.

\section{Exercises}

\begin{enumerate}
    \item Given the two parent chromosomes for a permutation problem:
    \begin{itemize}
        \item Parent 1: [1, 2, 7, 3, 4, 9, 8, 6, 5]
        \item Parent 2: [5, 4, 3, 9, 1, 2, 6, 8, 7]
    \end{itemize}
    \begin{enumerate}
        \item Perform Partial-Mapped Crossover (PMX) with cut points at positions 2 and 5
        \item Apply inversion mutation to the offspring with mutation segment from locus 2 to 5
    \end{enumerate}
    
    \item For a binary-encoded GA with chromosome length $L = 50$ and population size $N = 100$:
    \begin{enumerate}
        \item Calculate appropriate mutation probability using $P_m = 1/L$
        \item Calculate alternative mutation probability using $P_m = 1/(N \times L)$
        \item Discuss which might be more appropriate and why
    \end{enumerate}
    
    \item Design a mutation operator for a real-valued chromosome representing $(x, y)$ coordinates where $x, y \in [-100, 100]$:
    \begin{enumerate}
        \item Implement uniform mutation
        \item Implement Gaussian mutation with $\sigma = 5$
        \item Compare the expected behavior of both operators
    \end{enumerate}
    
    \item Implement and compare three generation update strategies:
    \begin{enumerate}
        \item Generational replacement with elitism ($k=2$)
        \item Steady-state with replacement of worst individuals
        \item Steady-state with replacement of oldest individuals
    \end{enumerate}
    Discuss scenarios where each might be preferred.
    
    \item For the test function $f(x_1, x_2) = x_1^2 + x_2^2$ with $x_1, x_2 \in [-10, 10]$:
    \begin{enumerate}
        \item Design a complete GA including all parameters
        \item Run experiments with different parameter combinations
        \item Analyze which parameters have the most significant impact
        \item Propose an optimal parameter configuration based on your results
    \end{enumerate}
\end{enumerate}
